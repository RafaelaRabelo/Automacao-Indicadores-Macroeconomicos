{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Acesso negado: 'C:\\\\Users\\\\DXX7'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 21\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# Caminho absoluto para a pasta onde os arquivos serão salvos\u001b[39;00m\n\u001b[0;32m     20\u001b[0m pasta_destino \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mC:\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mUsers\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mDXX7\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mPETROBRAS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mIntegração de Dados - SUB ORC - Documentos\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mINDICES MACROECONOMICOS\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mScripts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mScripts\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mCAMBIO\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mArquivos do Script\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m---> 21\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmakedirs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpasta_destino\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexist_ok\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Função para limpar dados, mantendo apenas o último horário por data\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlimpar_dados\u001b[39m(file_name):\n",
      "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "    \u001b[1;31m[... skipping similar frames: makedirs at line 215 (4 times)]\u001b[0m\n",
      "File \u001b[1;32m<frozen os>:215\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "File \u001b[1;32m<frozen os>:225\u001b[0m, in \u001b[0;36mmakedirs\u001b[1;34m(name, mode, exist_ok)\u001b[0m\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Acesso negado: 'C:\\\\Users\\\\DXX7'"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "from datetime import datetime, timedelta\n",
    "import io\n",
    "import os\n",
    "\n",
    "# Lista de moedas\n",
    "moedas = ['CAD', 'USD', 'SEK', 'NOK', 'JPY', 'GBP', 'EUR', 'DKK', 'AUD', 'CHF']\n",
    "\n",
    "# Data final sendo o dia de hoje no formato MM-DD-YYYY\n",
    "data_final = datetime.today().strftime('%m-%d-%Y')\n",
    "\n",
    "# Data inicial\n",
    "data_inicial = '12-30-1999'\n",
    "\n",
    "# URL base da API\n",
    "url_base = 'https://olinda.bcb.gov.br/olinda/servico/PTAX/versao/v1/odata/CotacaoMoedaPeriodo'\n",
    "\n",
    "# Caminho absoluto para a pasta onde os arquivos serão salvos\n",
    "pasta_destino = r'xxxx'\n",
    "os.makedirs(pasta_destino, exist_ok=True)\n",
    "\n",
    "# Função para limpar dados, mantendo apenas o último horário por data\n",
    "def limpar_dados(file_name):\n",
    "    if os.path.exists(file_name):\n",
    "        dados = pd.read_csv(file_name, sep=';')\n",
    "        if not dados.empty:\n",
    "            # Convertendo para datetime para facilitar a manipulação\n",
    "            dados['dataHoraCotacao'] = pd.to_datetime(dados['dataHoraCotacao'])\n",
    "            dados['data'] = dados['dataHoraCotacao'].dt.date\n",
    "            # Mantém apenas o último horário disponível para cada data\n",
    "            dados_limpos = dados.sort_values('dataHoraCotacao').groupby('data').tail(1)\n",
    "            # Remove a coluna auxiliar 'data'\n",
    "            dados_limpos = dados_limpos.drop(columns=['data'])\n",
    "            # Adiciona a coluna 'moeda'\n",
    "            dados_limpos['moeda'] = dados_limpos['moeda'].fillna(method='ffill')  # Preenche a coluna 'moeda' se necessário\n",
    "            # Salva os dados limpos de volta ao arquivo CSV\n",
    "            dados_limpos.to_csv(file_name, sep=';', index=False)\n",
    "            print(f'Dados limpos no arquivo {file_name}')\n",
    "        else:\n",
    "            print(f'O arquivo {file_name} está vazio e não requer limpeza.')\n",
    "    else:\n",
    "        print(f'O arquivo {file_name} não existe.')\n",
    "\n",
    "# Função para baixar e adicionar dados ao arquivo existente\n",
    "def baixar_dados_incremental(moeda, data_final):\n",
    "    file_name = os.path.join(pasta_destino, f'{moeda}_cotacoes.csv')\n",
    "    \n",
    "    # Se o arquivo já existe, encontrar a última data\n",
    "    if os.path.exists(file_name):\n",
    "        # Ler o arquivo existente\n",
    "        dados_existentes = pd.read_csv(file_name, sep=';')\n",
    "        if not dados_existentes.empty:\n",
    "            ultima_data = pd.to_datetime(dados_existentes['dataHoraCotacao'].max())\n",
    "            data_inicial = (ultima_data + timedelta(days=1)).strftime('%m-%d-%Y')\n",
    "        else:\n",
    "            # Se o arquivo existe mas está vazio, use a data inicial original\n",
    "            data_inicial = '12-30-1999'\n",
    "    else:\n",
    "        # Se o arquivo não existe, use a data inicial original\n",
    "        data_inicial = '12-30-1999'\n",
    "    \n",
    "    url = f\"{url_base}(moeda=@moeda,dataInicial=@dataInicial,dataFinalCotacao=@dataFinalCotacao)?@moeda='{moeda}'&@dataInicial='{data_inicial}'&@dataFinalCotacao='{data_final}'&$top=1000000&$format=text/csv&$select=paridadeVenda,cotacaoVenda,dataHoraCotacao\"\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code == 200:\n",
    "        # Usa o módulo io para ler o conteúdo CSV da resposta\n",
    "        novos_dados = pd.read_csv(io.StringIO(response.text))\n",
    "        if not novos_dados.empty:\n",
    "            # Adiciona a coluna com o nome da moeda\n",
    "            novos_dados['moeda'] = moeda\n",
    "            \n",
    "            if os.path.exists(file_name):\n",
    "                # Se o arquivo existe, atualiza com os novos dados\n",
    "                dados_existentes = pd.read_csv(file_name, sep=';')\n",
    "                dados_existentes = pd.concat([dados_existentes, novos_dados], ignore_index=True)\n",
    "                # Salva todos os dados, incluindo os novos e os existentes, com a coluna 'moeda'\n",
    "                dados_existentes.to_csv(file_name, sep=';', index=False)\n",
    "            else:\n",
    "                # Se o arquivo não existe, cria um novo\n",
    "                novos_dados.to_csv(file_name, sep=';', index=False)\n",
    "                \n",
    "            print(f'Dados da moeda {moeda} foram atualizados em {file_name}')\n",
    "        else:\n",
    "            print(f'Nenhum dado novo disponível para a moeda {moeda}.')\n",
    "    else:\n",
    "        print(f'Falha ao baixar dados para a moeda {moeda}. Status code: {response.status_code}')\n",
    "\n",
    "    # Limpar dados após adicionar novos dados\n",
    "    limpar_dados(file_name)\n",
    "\n",
    "# Baixar dados de forma incremental para cada moeda\n",
    "for moeda in moedas:\n",
    "    baixar_dados_incremental(moeda, data_final)\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "from fredapi import Fred\n",
    "\n",
    "# Substitua 'your_api_key' pela sua chave de API do FRED\n",
    "api_key = '1bcbbf6cffa7aa308484d98a6078c54d'\n",
    "fred = Fred(api_key=api_key)\n",
    "\n",
    "# Definir a data inicial\n",
    "start_date = '1999-12-30'\n",
    "\n",
    "# Caminho para o arquivo CSV com as cotações USD/BRL\n",
    "caminho_arquivo_usd = r'xxxx'\n",
    "\n",
    "# Função para converter ponto em vírgula e para float\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        return float(value.replace(',', '.'))\n",
    "    except ValueError:\n",
    "        return value\n",
    "\n",
    "# Carregar os dados USD/BRL a partir do arquivo CSV\n",
    "try:\n",
    "    usd_brl_df = pd.read_csv(caminho_arquivo_usd, sep=';')\n",
    "    usd_brl_df['dataHoraCotacao'] = pd.to_datetime(usd_brl_df['dataHoraCotacao'])\n",
    "    usd_brl_df.set_index('dataHoraCotacao', inplace=True)\n",
    "    \n",
    "    # Converter a coluna 'cotacaoVenda' de string para float\n",
    "    usd_brl_df['cotacaoVenda'] = usd_brl_df['cotacaoVenda'].apply(convert_to_float)\n",
    "    \n",
    "    # Extrair a última cotação do dia\n",
    "    usd_brl_df['Data'] = usd_brl_df.index.date\n",
    "    last_hour_cotations = usd_brl_df.groupby('Data').apply(lambda x: x.iloc[-1])\n",
    "    last_hour_cotations.set_index('Data', inplace=True)\n",
    "    \n",
    "    # Selecionar a coluna 'cotacaoVenda' para a cotação USD/BRL\n",
    "    usd_brl_last_hour = last_hour_cotations[['cotacaoVenda']]\n",
    "    usd_brl_last_hour.rename(columns={'cotacaoVenda': 'Cotacao USD/BRL'}, inplace=True)\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao carregar dados do arquivo CSV: {e}\")\n",
    "    usd_brl_last_hour = pd.DataFrame(columns=['Cotacao USD/BRL'])\n",
    "\n",
    "# Obter dados de taxas de câmbio USD/CNY do FRED\n",
    "try:\n",
    "    usd_cny = fred.get_series('DEXCHUS', start_date)\n",
    "    \n",
    "    # Criar DataFrame para USD/CNY\n",
    "    usd_cny_df = pd.DataFrame({\n",
    "        'Data': usd_cny.index,\n",
    "        'Cotacao USD/CNY': usd_cny.values\n",
    "    })\n",
    "    usd_cny_df.set_index('Data', inplace=True)\n",
    "    \n",
    "    # Reindexar o DataFrame USD/CNY para combinar com o DataFrame USD/BRL\n",
    "    combined_df = usd_cny_df.reindex(usd_brl_last_hour.index).fillna(method='ffill')\n",
    "    \n",
    "    # Calcular a paridade CNY/USD\n",
    "    combined_df['Paridade CNY/USD'] = 1 / combined_df['Cotacao USD/CNY']\n",
    "    \n",
    "    # Adicionar a cotação USD/BRL ao DataFrame combinado\n",
    "    final_df = combined_df.join(usd_brl_last_hour)\n",
    "    \n",
    "    # Calcular a cotação CNY/BRL\n",
    "    final_df['Cotacao CNY/BRL'] = final_df['Cotacao USD/BRL'] / final_df['Cotacao USD/CNY']\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"Erro ao obter dados do FRED: {e}\")\n",
    "    final_df = pd.DataFrame(columns=['Paridade CNY/USD', 'Cotacao USD/BRL', 'Cotacao CNY/BRL'])\n",
    "\n",
    "# Remover colunas desnecessárias e renomear as colunas restantes\n",
    "final_df.drop(columns=['Cotacao USD/CNY', 'Cotacao USD/BRL'], inplace=True, errors='ignore')\n",
    "final_df.rename(columns={\n",
    "    'Paridade CNY/USD': 'paridadeVenda',\n",
    "    'Cotacao CNY/BRL': 'cotacaoVenda'\n",
    "}, inplace=True)\n",
    "final_df.index.name = 'dataHoraCotacao'\n",
    "\n",
    "# Adicionar a coluna 'moeda' com o valor 'CNY'\n",
    "final_df['moeda'] = 'CNY'\n",
    "\n",
    "# Exibir o DataFrame resultante\n",
    "print(final_df.head())\n",
    "\n",
    "# Exibir os valores da última data para depuração\n",
    "if not final_df.empty:\n",
    "    last_date = final_df.index[-1]\n",
    "    print(f\"\\nValores para a última data ({last_date}):\")\n",
    "    print(f\"  Cotacao CNY/BRL: {final_df.loc[last_date, 'cotacaoVenda']}\")\n",
    "    print(f\"  Paridade CNY/USD: {final_df.loc[last_date, 'paridadeVenda']}\")\n",
    "\n",
    "# Função para formatar valores com vírgulas, mantendo todas as casas decimais\n",
    "def format_with_comma(value):\n",
    "    try:\n",
    "        # Converte o valor para string e substitui o ponto por vírgula\n",
    "        return str(value).replace('.', ',')\n",
    "    except ValueError:\n",
    "        return value\n",
    "\n",
    "# Aplicar a formatação com vírgula\n",
    "final_df_formatted = final_df.applymap(format_with_comma)\n",
    "final_df_formatted.index.name = 'dataHoraCotacao'\n",
    "\n",
    "# Caminho para salvar o arquivo CSV\n",
    "caminho_arquivo_final = r'xxxx'\n",
    "\n",
    "# Salvar o DataFrame em um arquivo CSV separado por ponto e vírgula\n",
    "final_df_formatted.to_csv(caminho_arquivo_final, sep=';', index=True)\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# Caminho absoluto para o arquivo CSV consolidado\n",
    "caminho_arquivo_consolidado = r'xxxx'\n",
    "\n",
    "# Verifique se o arquivo existe e apague-o\n",
    "if os.path.exists(caminho_arquivo_consolidado):\n",
    "    os.remove(caminho_arquivo_consolidado)\n",
    "    print(f'O arquivo {caminho_arquivo_consolidado} foi apagado.')\n",
    "else:\n",
    "    print(f'O arquivo {caminho_arquivo_consolidado} não existe.')\n",
    "\n",
    "# Caminho absoluto para a pasta onde os arquivos estão salvos\n",
    "pasta_destino = r'xxxx'\n",
    "\n",
    "# Caminho para o arquivo CSV consolidado\n",
    "caminho_arquivo_consolidado = os.path.join(pasta_destino, 'todas_as_moedas_cotacoes.csv')\n",
    "\n",
    "# Listar todos os arquivos CSV na pasta\n",
    "arquivos_csv = [f for f in os.listdir(pasta_destino) if f.endswith('_cotacoes.csv')]\n",
    "\n",
    "# Inicializar uma lista para armazenar os DataFrames\n",
    "lista_dfs = []\n",
    "\n",
    "# Ler e adicionar todos os arquivos CSV à lista de DataFrames\n",
    "for arquivo_csv in arquivos_csv:\n",
    "    caminho_arquivo = os.path.join(pasta_destino, arquivo_csv)\n",
    "    try:\n",
    "        # Ler o arquivo CSV\n",
    "        df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "        \n",
    "        # Converter a coluna 'dataHoraCotacao' para o formato de data\n",
    "        if 'dataHoraCotacao' in df.columns:\n",
    "            df['dataHoraCotacao'] = pd.to_datetime(df['dataHoraCotacao'], errors='coerce')\n",
    "            df['dataHoraCotacao'] = df['dataHoraCotacao'].dt.strftime('%d/%m/%Y')\n",
    "        \n",
    "        # Garantir que 'paridadeVenda' e 'cotacaoVenda' sejam numéricos\n",
    "        for coluna in ['paridadeVenda', 'cotacaoVenda']:\n",
    "            if coluna in df.columns:\n",
    "                # Substituir separador decimal por ponto para conversão\n",
    "                df[coluna] = df[coluna].astype(str).str.replace(',', '.', regex=False)\n",
    "                # Converter para número, definindo valores inválidos como NaN\n",
    "                df[coluna] = pd.to_numeric(df[coluna], errors='coerce')\n",
    "                # Reverter o separador decimal para vírgula após a conversão\n",
    "                df[coluna] = df[coluna].map(lambda x: f\"{x:,.6f}\".replace('.', ',') if pd.notna(x) else x)\n",
    "\n",
    "        # Adicionar a coluna 'moeda'\n",
    "        if 'moeda' not in df.columns:\n",
    "            df['moeda'] = arquivo_csv.split('_')[0]\n",
    "\n",
    "        lista_dfs.append(df)\n",
    "        print(f'{arquivo_csv} lido e formatado com sucesso.')\n",
    "    except Exception as e:\n",
    "        print(f'Erro ao ler {arquivo_csv}: {e}')\n",
    "\n",
    "# Concatenar todos os DataFrames em um único DataFrame\n",
    "if lista_dfs:\n",
    "    df_consolidado = pd.concat(lista_dfs, ignore_index=True)\n",
    "\n",
    "    # Salvar o DataFrame consolidado em um arquivo CSV separado por ponto e vírgula\n",
    "    df_consolidado.to_csv(caminho_arquivo_consolidado, sep=';', index=False, float_format='%.6f')\n",
    "    print(f'Arquivo consolidado criado com sucesso: {caminho_arquivo_consolidado}')\n",
    "else:\n",
    "    print('Nenhum arquivo CSV encontrado para consolidar.')\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "# Caminho para o arquivo CSV\n",
    "caminho_arquivo = r'xxxx'\n",
    "\n",
    "# Ler o arquivo CSV\n",
    "df = pd.read_csv(caminho_arquivo, sep=';')\n",
    "\n",
    "# Converter a coluna 'dataHoraCotacao' para datetime\n",
    "df['dataHoraCotacao'] = pd.to_datetime(df['dataHoraCotacao'], format='%d/%m/%Y')\n",
    "\n",
    "# Criar um DataFrame com todas as datas entre 30/12/1999 e hoje\n",
    "data_inicial = datetime(1999, 12, 30)\n",
    "data_atual = datetime.now()\n",
    "datas = pd.date_range(start=data_inicial, end=data_atual)\n",
    "\n",
    "# Criar um DataFrame vazio com as datas e moedas\n",
    "moedas = df['moeda'].unique()\n",
    "dados_completos = pd.MultiIndex.from_product([datas, moedas], names=['dataHoraCotacao', 'moeda'])\n",
    "df_completo = pd.DataFrame(index=dados_completos).reset_index()\n",
    "\n",
    "# Merge para preencher os valores\n",
    "df_completo = pd.merge(df_completo, df, on=['dataHoraCotacao', 'moeda'], how='left')\n",
    "\n",
    "# Preencher valores faltantes\n",
    "df_completo.sort_values(by=['moeda', 'dataHoraCotacao'], inplace=True)\n",
    "df_completo['paridadeVenda'].fillna(method='ffill', inplace=True)\n",
    "df_completo['cotacaoVenda'].fillna(method='ffill', inplace=True)\n",
    "\n",
    "# Filtrar para datas a partir de 01/01/2000\n",
    "data_filtro = datetime(2000, 1, 1)\n",
    "df_completo = df_completo[df_completo['dataHoraCotacao'] >= data_filtro]\n",
    "\n",
    "# Adicionar coluna com a última data disponível para cada moeda\n",
    "ultima_data_disponivel = df.groupby('moeda')['dataHoraCotacao'].max().reset_index()\n",
    "ultima_data_disponivel.columns = ['moeda', 'ultimaDataDisponivel']\n",
    "\n",
    "# Merge para adicionar a coluna de última data disponível\n",
    "df_completo = pd.merge(df_completo, ultima_data_disponivel, on='moeda', how='left')\n",
    "\n",
    "# Adicionar coluna com a data da última execução do script\n",
    "data_execucao = datetime.now().strftime('%d/%m/%Y %H:%M:%S')\n",
    "df_completo['dataExecucao'] = data_execucao\n",
    "\n",
    "# Sobrescrever o arquivo CSV original\n",
    "df_completo.to_csv(caminho_arquivo, sep=';', index=False)\n",
    "\n",
    "print(f\"Arquivo original sobrescrito com dados a partir de 01/01/2000: {caminho_arquivo}\")\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Carregar o arquivo CSV\n",
    "file_path = r\"xxxx\"\n",
    "df = pd.read_csv(file_path, sep=';', decimal=',')\n",
    "\n",
    "# Verificar as colunas disponíveis\n",
    "print(df.columns)\n",
    "\n",
    "# Converter colunas para numérico\n",
    "df['cotacaoVenda'] = pd.to_numeric(df['cotacaoVenda'], errors='coerce')\n",
    "df['paridadeVenda'] = pd.to_numeric(df['paridadeVenda'], errors='coerce')\n",
    "\n",
    "# Preencher valores ausentes usando ffill\n",
    "df['cotacaoVenda'].ffill(inplace=True)\n",
    "\n",
    "# Inspecionar o formato das datas no DataFrame\n",
    "print(df[['dataExecucao', 'ultimaDataDisponivel']].head())\n",
    "\n",
    "# Tentar converter as datas com um formato flexível\n",
    "df['dataExecucao'] = pd.to_datetime(df['dataExecucao'], errors='coerce', infer_datetime_format=True)\n",
    "df['ultimaDataDisponivel'] = pd.to_datetime(df['ultimaDataDisponivel'], errors='coerce', infer_datetime_format=True)\n",
    "\n",
    "# Verificar se as datas foram convertidas corretamente\n",
    "print(df[['dataExecucao', 'ultimaDataDisponivel']].head())\n",
    "\n",
    "# Tabela Cruzada de Cotações (em BRL)\n",
    "tabela_cotacao = df.pivot_table(index='dataHoraCotacao', columns='moeda', values='cotacaoVenda')\n",
    "# Garantir que o BRL esteja incluído\n",
    "tabela_cotacao['BRL'] = 1\n",
    "\n",
    "# Resetar o índice para 'dataHoraCotacao'\n",
    "tabela_cotacao.reset_index(inplace=True)\n",
    "\n",
    "# Tabela Cruzada de Paridades\n",
    "# Criar DataFrame para cotações em BRL\n",
    "cotacoes_brl = df.pivot_table(index='dataHoraCotacao', columns='moeda', values='cotacaoVenda', aggfunc='mean')\n",
    "cotacoes_brl['BRL'] = 1\n",
    "\n",
    "# Inicializar DataFrame para paridades\n",
    "paridades = pd.DataFrame(index=cotacoes_brl.index)\n",
    "\n",
    "# Calcular paridades\n",
    "moedas = cotacoes_brl.columns\n",
    "for moeda1 in moedas:\n",
    "    for moeda2 in moedas:\n",
    "        if moeda1 != moeda2:\n",
    "            paridade_col = f'{moeda1}/{moeda2}'\n",
    "            paridades[paridade_col] = cotacoes_brl[moeda1] / cotacoes_brl[moeda2]\n",
    "\n",
    "# Resetar os índices\n",
    "paridades.reset_index(inplace=True)\n",
    "tabela_cotacao.reset_index(inplace=True)\n",
    "\n",
    "# Adicionar colunas de dataExecucao e ultimaDataDisponivel nas tabelas\n",
    "if 'dataExecucao' in df.columns and 'ultimaDataDisponivel' in df.columns:\n",
    "    tabela_cotacao = pd.merge(tabela_cotacao, df[['dataHoraCotacao', 'dataExecucao', 'ultimaDataDisponivel']].drop_duplicates(), on='dataHoraCotacao', how='left')\n",
    "    paridades = pd.merge(paridades, df[['dataHoraCotacao', 'dataExecucao', 'ultimaDataDisponivel']].drop_duplicates(), on='dataHoraCotacao', how='left')\n",
    "\n",
    "# Função para formatar valores numéricos com 4 casas decimais\n",
    "def format_decimal(df):\n",
    "    df = df.copy()  # Evitar problemas com fragmentação\n",
    "    for col in df.columns:\n",
    "        if pd.api.types.is_numeric_dtype(df[col]):\n",
    "            df[col] = df[col].apply(lambda x: '{:,.4f}'.format(x).replace('.', ',') if pd.notna(x) else '')\n",
    "    return df\n",
    "\n",
    "# Aplicar a formatação\n",
    "tabela_cotacao_formatada = format_decimal(tabela_cotacao)\n",
    "paridades_formatada = format_decimal(paridades)\n",
    "\n",
    "# Salvar os DataFrames em arquivos CSV\n",
    "tabela_cotacao_formatada.to_csv(r\"xxxx\", sep=';', index=False)\n",
    "paridades_formatada.to_csv(r\"xxxx\", sep=';', index=False)\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV original\n",
    "file_path = r\"xxxx\"\n",
    "\n",
    "# Ler o arquivo CSV com separador \";\"\n",
    "df = pd.read_csv(file_path, sep=\";\")\n",
    "\n",
    "# Selecionar as colunas necessárias\n",
    "colunas_desejadas = [\n",
    "    \"dataHoraCotacao\", \"EUR/BRL\", \"EUR/GBP\", \"EUR/USD\", \"BRL/EUR\", \"BRL/GBP\", \"BRL/USD\",\n",
    "    \"GBP/BRL\", \"GBP/EUR\", \"GBP/USD\", \"USD/BRL\", \"USD/GBP\", \"USD/EUR\", \"ultimaDataDisponivel\"\n",
    "]\n",
    "\n",
    "df_selecionado = df[colunas_desejadas]\n",
    "\n",
    "# Desempilhar os dados de câmbio para um formato longo\n",
    "df_transformado = df_selecionado.melt(\n",
    "    id_vars=[\"dataHoraCotacao\", \"ultimaDataDisponivel\"], \n",
    "    var_name=\"Paridade\", \n",
    "    value_name=\"Valor\"\n",
    ")\n",
    "\n",
    "# Encontrar os valores das últimas datas para cada paridade\n",
    "df_ultima_data = df_transformado[df_transformado['dataHoraCotacao'] == df_transformado['ultimaDataDisponivel']]\n",
    "\n",
    "# Realizar o merge para adicionar a coluna Valor-1\n",
    "df_resultado = pd.merge(df_transformado, df_ultima_data[['Paridade', 'Valor']], \n",
    "                        on='Paridade', suffixes=('', '-1'), how='left')\n",
    "\n",
    "# Limpeza: substituir vírgulas por pontos, remover espaços e garantir que os valores sejam numéricos\n",
    "df_resultado['Valor'] = df_resultado['Valor'].replace({',': '.'}, regex=True)  # Substitui vírgulas por pontos\n",
    "df_resultado['Valor-1'] = df_resultado['Valor-1'].replace({',': '.'}, regex=True)  # Substitui vírgulas por pontos\n",
    "\n",
    "# Remover espaços extras (se existirem)\n",
    "df_resultado['Valor'] = df_resultado['Valor'].str.strip()\n",
    "df_resultado['Valor-1'] = df_resultado['Valor-1'].str.strip()\n",
    "\n",
    "# Converter para valores numéricos (float), forçando a conversão correta\n",
    "df_resultado['Valor'] = pd.to_numeric(df_resultado['Valor'], errors='coerce')\n",
    "df_resultado['Valor-1'] = pd.to_numeric(df_resultado['Valor-1'], errors='coerce')\n",
    "\n",
    "# Calcular a variação percentual entre \"Valor\" (mais antigo) e \"Valor-1\" (mais recente)\n",
    "df_resultado['Variação Percentual'] = ((df_resultado['Valor'] ) / df_resultado['Valor-1'])\n",
    "\n",
    "# Converter os valores numéricos das colunas 'Valor', 'Valor-1' e 'Variação Percentual' para string e substituir o ponto por vírgula\n",
    "df_resultado['Valor'] = df_resultado['Valor'].apply(lambda x: str(x).replace('.', ',') if pd.notna(x) else x)\n",
    "df_resultado['Valor-1'] = df_resultado['Valor-1'].apply(lambda x: str(x).replace('.', ',') if pd.notna(x) else x)\n",
    "df_resultado['Variação Percentual'] = df_resultado['Variação Percentual'].apply(lambda x: str(x).replace('.', ',') if pd.notna(x) else x)\n",
    "\n",
    "\n",
    "# Alterar os nomes das colunas\n",
    "df_resultado.rename(columns={\n",
    "    'dataHoraCotacao': 'Data da paridade',\n",
    "    'ultimaDataDisponivel': 'Ultima Data Disponivel',\n",
    "    'Variação Percentual': '%'\n",
    "}, inplace=True)\n",
    "\n",
    "# Exibir o resultado para verificar\n",
    "print(df_resultado.head())\n",
    "\n",
    "# Salvar o DataFrame resultante em um novo arquivo CSV\n",
    "output_path = r\"xxxx\"\n",
    "df_resultado.to_csv(output_path, sep=\";\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
