{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo filtrado e atualizado com a data mais recente salvo em: C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\SAP\\Indices_SAP_filtrado_com_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FNEQ\\AppData\\Local\\Temp\\ipykernel_6876\\335456466.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_sap_filtrado['data'] = pd.to_datetime(df_sap_filtrado['data'], format='%d/%m/%Y', errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV do SAP\n",
    "caminho_sap = r'xxxx'\n",
    "\n",
    "# Abrir o arquivo CSV do SAP com o separador ';'\n",
    "df_sap = pd.read_csv(caminho_sap, sep=';')\n",
    "\n",
    "# Filtrar os dados para os códigos específicos\n",
    "codigos_desejados = [\"SAP - IBGAC\", \"SAP - IGP\", \"SAP - IPAMB\"]\n",
    "df_sap_filtrado = df_sap[df_sap['codigo'].isin(codigos_desejados)]\n",
    "\n",
    "# Garantir que a coluna 'data' seja interpretada corretamente\n",
    "df_sap_filtrado['data'] = pd.to_datetime(df_sap_filtrado['data'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Agrupar pelos códigos e pegar a data mais recente\n",
    "df_sap_filtrado_mais_recente = df_sap_filtrado.groupby('codigo')['data'].max().reset_index()\n",
    "\n",
    "# Mesclar os dois dataframes com base na coluna \"codigo\"\n",
    "df_sap_filtrado_com_data = pd.merge(df_sap_filtrado, df_sap_filtrado_mais_recente[['codigo', 'data']], on='codigo', how='left')\n",
    "\n",
    "# Renomear a coluna 'data' para 'Data_mais_recente'\n",
    "df_sap_filtrado_com_data.rename(columns={'data': 'Data_mais_recente'}, inplace=True)\n",
    "\n",
    "# Salvar o dataframe resultante em um novo arquivo CSV\n",
    "novo_caminho_sap = r'C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\SAP\\Indices_SAP_filtrado_com_data.csv'\n",
    "df_sap_filtrado_com_data.to_csv(novo_caminho_sap, sep=';', index=False)\n",
    "\n",
    "print(f\"Arquivo filtrado e atualizado com a data mais recente salvo em: {novo_caminho_sap}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo filtrado e atualizado com a data mais recente e a coluna 'moedas relacionadas' salvo em: C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\FRED\\Dados de saida\\Dados_de_saida_filtrado_com_data.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FNEQ\\AppData\\Local\\Temp\\ipykernel_6876\\3660320611.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_fred_filtrado['data'] = pd.to_datetime(df_fred_filtrado['data'], format='%d/%m/%Y', errors='coerce')\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV do FRED\n",
    "caminho_fred = r'xxxx'\n",
    "\n",
    "# Abrir o arquivo CSV do FRED com o separador ';'\n",
    "df_fred = pd.read_csv(caminho_fred, sep=';')\n",
    "\n",
    "# Filtrar os dados para os códigos específicos\n",
    "codigos_desejados = [\"FRED - PCU333132333132\", \"FRED - WPUFD49207\", \"FRED - WPU07\"]\n",
    "df_fred_filtrado = df_fred[df_fred['codigo'].isin(codigos_desejados)]\n",
    "\n",
    "# Garantir que a coluna 'data' seja interpretada corretamente\n",
    "df_fred_filtrado['data'] = pd.to_datetime(df_fred_filtrado['data'], format='%d/%m/%Y', errors='coerce')\n",
    "\n",
    "# Agrupar pelos códigos e pegar a data mais recente\n",
    "df_fred_filtrado_mais_recente = df_fred_filtrado.groupby('codigo')['data'].max().reset_index()\n",
    "\n",
    "# Mesclar os dois dataframes com base na coluna \"codigo\"\n",
    "df_fred_filtrado_com_data = pd.merge(df_fred_filtrado, df_fred_filtrado_mais_recente[['codigo', 'data']], on='codigo', how='left')\n",
    "\n",
    "# Renomear a coluna 'data' para 'Data_mais_recente'\n",
    "df_fred_filtrado_com_data.rename(columns={'data': 'Data_mais_recente'}, inplace=True)\n",
    "\n",
    "# Adicionar a nova coluna 'moedas relacionadas' com o valor 'USD'\n",
    "df_fred_filtrado_com_data['moedas relacionadas'] = 'USD'\n",
    "\n",
    "# Salvar o dataframe resultante em um novo arquivo CSV\n",
    "novo_caminho_fred = r'C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\FRED\\Dados de saida\\Dados_de_saida_filtrado_com_data.csv'\n",
    "df_fred_filtrado_com_data.to_csv(novo_caminho_fred, sep=';', index=False)\n",
    "\n",
    "print(f\"Arquivo filtrado e atualizado com a data mais recente e a coluna 'moedas relacionadas' salvo em: {novo_caminho_fred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  codigo                             nome_completo Data_do_ultimo_dado  \\\n",
      "0   IGPM  Índice Geral de Preços do Mercado - IGPM          01/12/2024   \n",
      "\n",
      "  Data_de_atualizacao_da_base  \n",
      "0         2024-12-27 10:35:46  \n",
      "Dimensões do arquivo IGPM_resumo: (1, 4)\n",
      "Arquivo com a coluna 'data_y' e 'data_x' atualizado e salvo em: C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\FGV\\IGP-M_saida_com_data_y.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FNEQ\\AppData\\Local\\Temp\\ipykernel_6876\\3283166031.py:49: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_igp_m['data_x'] = pd.to_datetime(df_igp_m['data_x'], errors='coerce')  # Converter para datetime\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV do IGP-M\n",
    "caminho_igp_m = r'xxxx'\n",
    "\n",
    "# Abrir o arquivo CSV do IGP-M com o separador ';'\n",
    "df_igp_m = pd.read_csv(caminho_igp_m, sep=';', encoding='utf-8')\n",
    "\n",
    "# Caminho do arquivo IGPM_resumo para obter a data da célula C2\n",
    "caminho_igpm_resumo = r'xxxx'\n",
    "\n",
    "# Ler o arquivo IGPM_resumo\n",
    "df_igpm_resumo = pd.read_csv(caminho_igpm_resumo, sep=';', encoding='utf-8')\n",
    "\n",
    "# Mostrar as primeiras linhas do arquivo IGPM_resumo para entender seu formato\n",
    "print(df_igpm_resumo.head())\n",
    "\n",
    "# Verificar as dimensões do arquivo IGPM_resumo\n",
    "print(f\"Dimensões do arquivo IGPM_resumo: {df_igpm_resumo.shape}\")\n",
    "\n",
    "# Verificar se o arquivo tem ao menos 2 linhas e 3 colunas\n",
    "if df_igpm_resumo.shape[0] > 0 and df_igpm_resumo.shape[1] > 2:\n",
    "    # Obter a data da célula C2 (segunda linha e terceira coluna) -> 1st data line, 3rd column\n",
    "    data_c2 = df_igpm_resumo.iloc[0, 2]  # Linha 0 (segunda linha de dados), coluna 2 (terceira coluna)\n",
    "    \n",
    "    # Converter a data no formato 'dd/mm/yyyy'\n",
    "    data_c2 = pd.to_datetime(data_c2, format='%d/%m/%Y', errors='coerce')\n",
    "else:\n",
    "    print(\"O arquivo 'IGPM_resumo.csv' não tem as linhas ou colunas necessárias.\")\n",
    "    data_c2 = None\n",
    "\n",
    "# Se a data foi encontrada e convertida corretamente\n",
    "if data_c2 is not None:\n",
    "    df_igp_m['data_y'] = data_c2.strftime('%d/%m/%Y')  # Adiciona a coluna 'data_y' com a data de C2\n",
    "\n",
    "    # Adicionar as outras colunas conforme solicitado\n",
    "    df_igp_m['codigo'] = 'FGV - IGPM'\n",
    "    df_igp_m['moedas relacionadas'] = 'BRL'\n",
    "    df_igp_m['nome_completo'] = 'FGV - IGPM - INDICE GERAL DE PRECO DO MERCADO'\n",
    "    df_igp_m['fonte'] = 'FGV'\n",
    "\n",
    "    # Renomear as colunas conforme solicitado\n",
    "    df_igp_m.rename(columns={\n",
    "        'Data': 'data_x',\n",
    "        'Índice Geral de Preços - IGP-M(200045)': 'valor'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Garantir que a coluna 'data_x' tenha o mesmo formato que 'data_y'\n",
    "    df_igp_m['data_x'] = pd.to_datetime(df_igp_m['data_x'], errors='coerce')  # Converter para datetime\n",
    "    df_igp_m['data_x'] = df_igp_m['data_x'].dt.strftime('%d/%m/%Y')  # Formatá-la no formato desejado\n",
    "\n",
    "    # Salvar o dataframe resultante em um novo arquivo CSV\n",
    "    novo_caminho_igp_m = r'xxxx'\n",
    "    df_igp_m.to_csv(novo_caminho_igp_m, sep=';', index=False, encoding='utf-8')\n",
    "\n",
    "    print(f\"Arquivo com a coluna 'data_y' e 'data_x' atualizado e salvo em: {novo_caminho_igp_m}\")\n",
    "else:\n",
    "    print(\"Não foi possível adicionar a coluna 'data_y' porque a data da célula C2 não foi encontrada.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo salvo com sucesso em: C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\FGV\\Consolidado_IGPM_FRED_SAP.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Carregar as três planilhas\n",
    "caminho_igp_m = r'xxxx'\n",
    "caminho_fred = r'xxxx'\n",
    "caminho_sap = r'xxxx'\n",
    "\n",
    "# Ler os três arquivos CSV\n",
    "df_igp_m = pd.read_csv(caminho_igp_m, sep=';')\n",
    "df_fred = pd.read_csv(caminho_fred, sep=';')\n",
    "df_sap = pd.read_csv(caminho_sap, sep=';')\n",
    "\n",
    "# Certificar que todos os DataFrames tenham as mesmas colunas\n",
    "df_igp_m = df_igp_m[['data_x', 'valor', 'data_y', 'codigo', 'moedas relacionadas', 'nome_completo', 'fonte']]\n",
    "df_fred = df_fred[['data_x', 'valor', 'data_y', 'codigo', 'moedas relacionadas', 'nome_completo', 'fonte']]\n",
    "df_sap = df_sap[['data_x', 'valor', 'data_y', 'codigo', 'moedas relacionadas', 'nome_completo', 'fonte']]\n",
    "\n",
    "# Empilhar as planilhas em um único DataFrame\n",
    "df_combined = pd.concat([df_igp_m, df_fred, df_sap], ignore_index=True)\n",
    "\n",
    "df_ultima_data = df_combined.loc[df_combined.groupby('codigo')['data_x'].idxmax()]\n",
    "\n",
    "# Realizar um merge para adicionar a coluna 'valor-1' com o valor da última data de cada 'codigo'\n",
    "df_combined = pd.merge(df_combined, df_ultima_data[['codigo', 'valor']], \n",
    "                        on='codigo', suffixes=('', '-1'), how='left')\n",
    "\n",
    "# Salvar o DataFrame final em um arquivo CSV\n",
    "output_path = r'xxxx'  # Altere este caminho conforme necessário\n",
    "df_combined.to_csv(output_path, index=False, sep=';')\n",
    "\n",
    "# Exibir mensagem de confirmação\n",
    "print(f\"Arquivo salvo com sucesso em: {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dados tratados salvos no arquivo C:\\Users\\FNEQ\\PETROBRAS\\Integração de Dados - SUB ORC - Scripts\\Scripts\\FGV\\Consolidado_IGPM_FRED_SAP.csv com vírgula como separador decimal.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\FNEQ\\AppData\\Local\\Temp\\ipykernel_6876\\1971881569.py:70: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\n",
      "  df = df.applymap(lambda x: str(x).replace('.', ',') if isinstance(x, (float, int)) else x)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "\n",
    "# Caminho do arquivo CSV\n",
    "file_path = r'xxxx'\n",
    "\n",
    "# Lendo o arquivo CSV com numpy\n",
    "data = np.genfromtxt(file_path, delimiter=';', dtype=None, encoding='latin1', names=True)\n",
    "\n",
    "# Função para remover espaços extras de um valor\n",
    "def remove_spaces(value):\n",
    "    if isinstance(value, str):\n",
    "        return value.strip()\n",
    "    return value\n",
    "\n",
    "# Função para tratar e converter valores numéricos com vírgulas e pontos\n",
    "def convert_to_float(value):\n",
    "    try:\n",
    "        # Remove separadores de milhares (pontos) e substitui vírgulas por ponto decimal\n",
    "        cleaned_value = value.replace('.', '').replace(',', '.')\n",
    "        return float(cleaned_value)\n",
    "    except ValueError:\n",
    "        return None  # Retorna None se não for possível converter\n",
    "\n",
    "# Função para converter data para formato datetime\n",
    "def convert_to_date(value):\n",
    "    try:\n",
    "        return datetime.strptime(value, '%d/%m/%Y')\n",
    "    except ValueError:\n",
    "        try:\n",
    "            return datetime.strptime(value, '%Y-%m-%d')\n",
    "        except ValueError:\n",
    "            return value\n",
    "\n",
    "# Aplicando as funções de limpeza nas colunas\n",
    "cleaned_data = []\n",
    "for row in data:\n",
    "    cleaned_row = [\n",
    "        convert_to_date(remove_spaces(row[0])),   # data_x\n",
    "        convert_to_float(remove_spaces(row[1])),  # valor\n",
    "        convert_to_date(remove_spaces(row[2])),   # data_y\n",
    "        remove_spaces(row[3]),                    # codigo\n",
    "        remove_spaces(row[4]),                    # moedas relacionadas\n",
    "        remove_spaces(row[5]),                    # nome_completo\n",
    "        remove_spaces(row[6]),                    # fonte\n",
    "        convert_to_float(remove_spaces(row[7]))   # valor-1\n",
    "    ]\n",
    "    cleaned_data.append(tuple(cleaned_row))\n",
    "\n",
    "# Calculando a porcentagem entre (valor-1) e (valor)\n",
    "for i, row in enumerate(cleaned_data):\n",
    "    try:\n",
    "        # Calcular a porcentagem (valor-1 / valor)\n",
    "        if row[1] != 0:  # Garantir que 'valor' não seja zero\n",
    "            percentage = row[7] / row[1]\n",
    "        else:\n",
    "            percentage = None  # Ou algum valor de sua escolha se 'valor' for zero\n",
    "        # Adicionar a nova coluna \"%\", que será a porcentagem\n",
    "        cleaned_data[i] = row + (percentage,)\n",
    "    except Exception as e:\n",
    "        # Se ocorrer um erro (como divisão por zero), adicionar NaN\n",
    "        cleaned_data[i] = row + (None,)\n",
    "\n",
    "# Convertendo os dados tratados para um DataFrame do pandas\n",
    "columns = ['data_x', 'valor', 'data_y', 'codigo', 'moedas relacionadas', 'nome_completo', 'fonte', 'valor-1', '%']\n",
    "df = pd.DataFrame(cleaned_data, columns=columns)\n",
    "\n",
    "# Substituindo ponto por vírgula nos valores numéricos\n",
    "df = df.applymap(lambda x: str(x).replace('.', ',') if isinstance(x, (float, int)) else x)\n",
    "\n",
    "# Salvando os dados tratados de volta para o arquivo CSV, sem o índice\n",
    "df.to_csv(file_path, index=False, sep=';')\n",
    "\n",
    "# Exibindo a confirmação\n",
    "print(f\"Dados tratados salvos no arquivo {file_path} com vírgula como separador decimal.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
